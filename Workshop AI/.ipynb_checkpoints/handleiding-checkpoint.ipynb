{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a778f340-77ad-4976-9d3a-86559c91c35a",
   "metadata": {},
   "source": [
    "# Workshop AI\n",
    "\n",
    "Tijdens deze korte opleiding (ongeveer twee lesuren) maken de leerlingen een neuraal netwerk aan voor een zelfgekozen onderwerp, met behulp van **Google Teachable Machine**. Dit neuraal netwerk zal vervolgens communiceren met hardware, zodat het een fysiek systeem kan aansturen.  \n",
    "\n",
    "Voor de workshop is er gekozen voor een eenvoudig model dat op basis van beeldherkenning **twee verschillende toestanden** kan onderscheiden. Dit concept kan uitgebreid worden naar meerdere toestanden of complexere scenario‚Äôs, maar dat valt buiten het doel van deze workshop.  \n",
    "\n",
    "Onderstaande lijst toont enkele voorbeelden van mogelijke toepassingen. Leerlingen worden aangemoedigd om na deze workshop zelf creatieve experimenten uit te proberen en verder te onderzoeken hoe AI en hardware kunnen samenwerken.  \n",
    "\n",
    "- **Detectie van aanwezigheid in een lokaal** ‚Üí automatisch aansturen van verlichting  \n",
    "- **Herkenning van een specifieke persoon bij de voordeur** ‚Üí openen van een slim deurslot  \n",
    "- **Detectie van afvalsoorten (bijvoorbeeld PMD of restafval)** ‚Üí automatische opening van een vuilnisbak  \n",
    "- **Huisdierherkenning** ‚Üí automatisch voederen van een hond of kat op basis van aanwezigheid  \n",
    "- **Detectie van rook of dampontwikkeling** ‚Üí activeren van een ventilator of afzuiginstallatie  \n",
    "- **Automatische sortering van objecten** ‚Üí bijvoorbeeld in een fabriek of recyclagecentrum  \n",
    "- **Sportbegeleiding met AI** ‚Üí analyseren van lichaamshouding en feedback geven bij oefeningen  \n",
    "- **Spraakcommando‚Äôs voor domotica** ‚Üí stemgestuurde verlichting: \"licht aan\", \"licht uit\", of zelfs handgeklap als trigger  \n",
    "- **Noodsituaties detecteren via geluid** ‚Üí een AI-model dat \"help\" of \"hulp\" herkent en een alarm activeert  \n",
    "- **Slim dierenluik** ‚Üí openen van het luik op basis van het geluid van een blaffende hond of miauwende kat  \n",
    "- **Preventief machineonderhoud** ‚Üí herkennen van afwijkende geluiden (zoals kapotte lagers) en een waarschuwingssysteem activeren  \n",
    "- **Handgebaren als besturingsmethode** ‚Üí apparaten bedienen door specifieke gebaren, bijvoorbeeld een TV of volume regelen met een handbeweging  \n",
    "- **...**  \n",
    "\n",
    "Tijdens de workshop kunnen leerlingen een van deze toepassingen kiezen of zelf een idee uitwerken. Het belangrijkste doel is om inzicht te krijgen in hoe **neurale netwerken** worden getraind en hoe AI **herkenningspatronen** kan gebruiken om interactie met de echte wereld mogelijk te maken.  \n",
    "\n",
    "## Inleiding\n",
    "\n",
    "Het gebruik van **kunstmatige intelligentie (AI)** draait bijna altijd om √©√©n fundamenteel principe:  \n",
    "> **‚ÄúPatroonherkenning zonder voorkennis.‚Äù**  \n",
    "\n",
    "Met andere woorden: een AI-model kan leren om verschillen en overeenkomsten in gegevens (zoals afbeeldingen, geluiden of bewegingen) te herkennen, zonder dat het vooraf expliciete regels krijgt. Dit leerproces kan ondersteund worden door **positieve bekrachtiging**, waarbij de AI feedback krijgt over welke resultaten correct of fout zijn.  \n",
    "\n",
    "### Praktisch voorbeeld: Herkennen van handgebaren  \n",
    "\n",
    "In deze workshop gaan we een AI-model trainen om **handgebaren** te herkennen. Concreet willen we kunnen **onderscheiden** wanneer een **duim omhoog of omlaag** is.  \n",
    "\n",
    "Voor een mens is dit onderscheid eenvoudig, omdat wij al weten wat een hand en een duim zijn. Maar als we dit volledig **handmatig** zouden programmeren, zouden we beeldherkenning moeten implementeren. Dit zou betekenen dat we:  \n",
    "\n",
    "- De **vorm van een hand** moeten defini√´ren.  \n",
    "- Moeten bepalen **waar de duim zich bevindt**.  \n",
    "- Moeten herkennen of de duim **omhoog of omlaag** wijst.  \n",
    "\n",
    "Dit zou een **zeer complexe code** opleveren, die bovendien **alleen zou werken in een specifieke situatie**. Zelfs een kleine wijziging in de vereisten zou betekenen dat we **helemaal opnieuw moeten beginnen**.  \n",
    "\n",
    "Gelukkig biedt **AI hier een oplossing**! üöÄ  \n",
    "\n",
    "### Hoe werkt AI in beeldherkenning?  \n",
    "\n",
    "Wanneer we AI gebruiken, laten we het systeem **zelf leren** hoe het duimgebaren kan herkennen. Dit werkt als volgt:  \n",
    "\n",
    "1) Voldoende beeldmateriaal verzamelen: _We moeten het AI-model **leren** wat een duim omhoog en een duim omlaag is. Dit doen we door **veel verschillende afbeeldingen** van beide gebaren aan te leveren._\n",
    "2) Het AI-model laten trainen: _Het AI-algoritme gaat **zelf patronen ontdekken** in de beelden. Dit gebeurt via een **neuraal netwerk**, een wiskundig model dat patronen leert herkennen zonder dat wij zelf regels moeten schrijven._\n",
    "3) Testen en verbeteren: _Nadat het neurale netwerk getraind is, testen we of het **nauwkeurig genoeg** is. Als het model fouten maakt, kunnen we **extra beeldmateriaal toevoegen** om de herkenning te verbeteren._\n",
    "\n",
    "### Waarom is goed beeldmateriaal belangrijk?  \n",
    "\n",
    "Een AI-model kan alleen leren van wat het **ziet**. Als we bijvoorbeeld alleen afbeeldingen van een **lichte huidkleur** gebruiken, kan de AI moeite hebben met een **donkere huidkleur**.  AI weet namelijk **niet vanzelf** wat **hoofdzaak** en wat **bijzaak** is op een afbeelding.  \n",
    "\n",
    "üëâ Daarom is het belangrijk om **veel verschillende voorbeelden** te gebruiken, zoals:  \n",
    "\n",
    "- **Verschillende huidkleuren** (om geen bevooroordeelde AI te maken).  \n",
    "- **Verschillende achtergronden** (zodat AI leert dat de achtergrond niet belangrijk is).  \n",
    "- **Verschillende lichtomstandigheden** (zodat AI niet verward raakt door schaduw of helder licht).  \n",
    "\n",
    "Door een **gevarieerde dataset** en voldoende voorbeelden aan te bieden, zorg je ervoor dat het model **betrouwbaar en accuraat** wordt. üöÄ Hoe meer variatie we aanleveren, hoe beter AI zal generaliseren! üéØ  Kortom, **AI maakt beeldherkenning toegankelijk** zonder complexe code! üí°  \n",
    "\n",
    "## Google Teachable Machine\n",
    "\n",
    "In deze workshop gaan we gebruik maken van **Google Teachable Machine**, een [online tool](https://teachablemachine.withgoogle.com]) waarmee we **zonder programmeerkennis** een AI-model kunnen trainen.  \n",
    "\n",
    "```{figure} ./images/google_tm.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Google Teachable Machine.\n",
    "```\n",
    "\n",
    ":::{list-table} Voordelen van Google Teachable Machine  \n",
    ":header-rows: 1  \n",
    "\n",
    "* - ‚úÖ Eigenschap  \n",
    "  - üìå Beschrijving  \n",
    "* - **Gebruiksvriendelijk**  \n",
    "  - We hoeven geen code te schrijven.  \n",
    "* - **Snel trainen**  \n",
    "  - Binnen enkele minuten kan AI al een model leren.  \n",
    "* - **Exporteren en toepassen**  \n",
    "  - Het model kan gebruikt worden in **hardwaretoepassingen**, zoals een ESP32 om een **lamp te schakelen** of een **servo te bedienen**.  \n",
    ":::  \n",
    "\n",
    "### Neuraal netwerk aanmaken\n",
    "\n",
    "Als eerste stap gaan we een neuraal netwerk laten aanmaken door Google Teachable Machine (TM). Hiervoor moeten we eerst een model trainen. We hebben de keuze uit drie verschillende modellen:\n",
    "* Afbeeldingen\n",
    "* Audio\n",
    "* Houdingen\n",
    "\n",
    "```{figure} ./images/google_tm_new.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Meerkeuze voor een nieuw project.\n",
    "```\n",
    "\n",
    "Afhankelijk van de gewenste toepassing zullen we √©√©n van bovenstaande mogelijke projecten kiezen. Voor onze duimherkenning zou je eventueel kunnen twijfelen tussen \"afbeeldingen\" of \"houdingen\". De resolutie waarmee houdingen worden verwerkt is echter beperkt. Het herkennen van vingers is niet mogelijk, enkel de grotere ledematen (armen, benen, romp). We moeten hier dus kiezen voor \"afbeeldingen\".\n",
    "\n",
    "Als tweede keuze kunnen we kiezen of we het nieuwe project willen aanmaken a.d.h.v. standaard afbeeldingen of a.d.h.v. kleine afbeeldingen (in grijswaarden) die geschikt zijn voor embedded systemen. Het doel van deze workshop is een model trainen die zal gebruikt worden op een PC, dus kiezen we hier voor de standaard afbeeldingen. \n",
    "\n",
    "```{figure} ./images/google_tm_workflow.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Standaard workflow van een project.\n",
    "```\n",
    "\n",
    "De standaard workflow voor een project bestaat uit twee klassen, de mogelijkheid om het model te trainen en vervolgens de mogelijkheid om het model te testen/exporteren. De interface van Google TM is gebruiksvriendelijk. \n",
    "1) Geef de mogelijke toestanden dat je wil bekomen een duidelijke naam\n",
    "2) Kies voor webcam indien je niet beschikt over foto's. Indien je een dataset hebt kun je deze inladen.\n",
    "3) Train vervolgens je model\n",
    "4) Test vervolgens je model\n",
    "\n",
    "```{figure} ./images/google_tm_finish.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Getraind model.\n",
    "```\n",
    "### Exporteren neuraal model naar Keras model\n",
    "\n",
    "Eenmaal ons model getrained is, en we tevreden zijn over de werking van deze, kunnen we het model exporteren om te gebruiken buiten de Google TM omgeving. We hebben keuze uit verschillende modellen, namelijk:\n",
    "* Tensorflow.js (geschikt voor projecten op basis van browsers)\n",
    "* Tensorflow (geschikt voor systeemeigen projecten, zoals Python)\n",
    "* Tensorflow Lite (geschikt voor mobiele apparaten)\n",
    "\n",
    "```{figure} ./images/google_tm_export.png\n",
    ":width: 500px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Export mogelijkheden.\n",
    "```\n",
    "\n",
    "1) Aangezien wij het model wensen te gebruiken op onze PC is Python kiezen we hier voor het __tensorflow__ model.\n",
    "2) Conversietype laten we op __Keras__ staan.\n",
    "3) Kies vervolgens voor __Mijn model downloaden__.\n",
    "4) Onderaan vinden we voorbeeldcode voor __OpenCV Keras__ die we kunnen kopi√´ren.\n",
    "\n",
    "Het converteren van het model kan enkele minuten gebeuren. Nadat het model is gegenereerd zal deze automatisch gedownload worden als een converted_keras.zip bestand, waarbij in dit zip bestand twee bestanden kunnen aangetroffen worden:\n",
    "* keras_model.h5\n",
    "* labels.txt\n",
    "\n",
    "Beide bestanden gaan wij unzippen/kopi√´ren naar een projectmap die we aanmaken op ons systeem, waarbij de nodige Python code moet geplaatst worden die we grotendeels konden kopi√´ren vanuit Google TM.\n",
    "\n",
    "### Demo code gebruik\n",
    "\n",
    "Om de demo code te kunnen gebruiken in Python hebben we nood aan enkele externe bibliotheken, en gaan we eveneens ons model die we gedownload hebben moeten patchen.\n",
    "\n",
    "#### Installeren nodige bibliotheken\n",
    "\n",
    "Open in Thonny de _systeem shell_. Je vindt deze terug bij het tabblad _hulpmiddelen_.\n",
    "\n",
    "```{figure} ./images/thonny_shell.png\n",
    ":width: 500px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "De shell in Thonny.\n",
    "```\n",
    "\n",
    "Installeer vervolgens de nodige bibliotheken als volgt:\n",
    "\n",
    "```python\n",
    "pip install opencv-python tensorflow keras\n",
    "```\n",
    "\n",
    "_Hier gaat alles hopelijk goed??? Ik ben momenteel niet in de mogelijkheid dit te testen. Tijdens de workshop zullen er mogelijk problemen zijn._\n",
    "\n",
    "#### Testen OpenCV\n",
    "\n",
    "OpenCV is een vrij grote bibliotheek die toelaat beeldbewerking in Python te doen. Onder beeldbewerking zit eveneens het aanmaken van afbeeldingen die ingelezen kunnen worden via de systeemcamera. Als eerste zullen we dit dan ook testen naar werking toe.\n",
    "\n",
    "```python\n",
    "import cv2 as cv\n",
    "\n",
    "cap = cv.VideoCapture(0)\n",
    "while True:\n",
    "    _, img = cap.read()\n",
    "    cv.imshow(\"Webcam\", img)\n",
    "    cv.waitKey(1)\n",
    "```\n",
    "\n",
    "Als alles goed gaat zou je na een aantal seconden het beeld van je webcamera moeten kunnen zien. Het afsluiten van het beeld kan enkel en alleen maar door het script te stoppen, dit via de knop _stop_ of via _ctrl+c_. _Opgelet! Indien Google TM nog openstaat met de webcamera actief zal dit niet werken._\n",
    "\n",
    "#### Testen AI\n",
    "\n",
    "Als tweede test controleren we of alle bibliotheken (tesorflow & keras) voor het AI model ge√Ønstalleerd zijn. We kopi√´ren hiervoor de code uit Google TM en plaatsen dit in ons script.\n",
    "\n",
    "```python\n",
    "from keras.models import load_model  # TensorFlow is required for Keras to work\n",
    "import cv2  # Install opencv-python\n",
    "import numpy as np\n",
    "\n",
    "# Disable scientific notation for clarity\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "# Load the model\n",
    "model = load_model(\"keras_Model.h5\", compile=False)\n",
    "\n",
    "# Load the labels\n",
    "class_names = open(\"labels.txt\", \"r\").readlines()\n",
    "\n",
    "# CAMERA can be 0 or 1 based on default camera of your computer\n",
    "camera = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Grab the webcamera's image.\n",
    "    ret, image = camera.read()\n",
    "\n",
    "    # Resize the raw image into (224-height,224-width) pixels\n",
    "    image = cv2.resize(image, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Show the image in a window\n",
    "    cv2.imshow(\"Webcam Image\", image)\n",
    "\n",
    "    # Make the image a numpy array and reshape it to the models input shape.\n",
    "    image = np.asarray(image, dtype=np.float32).reshape(1, 224, 224, 3)\n",
    "\n",
    "    # Normalize the image array\n",
    "    image = (image / 127.5) - 1\n",
    "\n",
    "    # Predicts the model\n",
    "    prediction = model.predict(image)\n",
    "    index = np.argmax(prediction)\n",
    "    class_name = class_names[index]\n",
    "    confidence_score = prediction[0][index]\n",
    "\n",
    "    # Print prediction and confidence score\n",
    "    print(\"Class:\", class_name[2:], end=\"\")\n",
    "    print(\"Confidence Score:\", str(np.round(confidence_score * 100))[:-2], \"%\")\n",
    "\n",
    "    # Listen to the keyboard for presses.\n",
    "    keyboard_input = cv2.waitKey(1)\n",
    "\n",
    "    # 27 is the ASCII for the esc key on your keyboard.\n",
    "    if keyboard_input == 27:\n",
    "        break\n",
    "\n",
    "camera.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "Als alles \"goed\" gaat krijgen we in de CLI enkele rode waarschuwingen over afwijkingen/afrondingsfouten die we kunnen negeren. Uiteindelijk stopt de code door een `Exception`.\n",
    "\n",
    "> Exception encountered: Unrecognized keyword arguments passed to DepthwiseConv2D: {'groups': 1}\n",
    "\n",
    "Dit betekent dat al onze bibiliotheken correct zijn ge√Ønstalleerd, maar dat bij Google TM het model is ge√´xporteerd met een bepaald extra argument die toegevoegd is, waarmee de bibliotheken geen weg kunnen. We gaan hiervoor ons model patchen met volgende code (die slechts √©√©n keer moet uitgevoerd worden, en dit na het downloaden van het model). _Vergeet de code niet op te slaan in dezelfde map als deze van het model!_\n",
    "\n",
    "```python\n",
    "# hack to change model config from keras 2->3 compliant\n",
    "import h5py\n",
    "f = h5py.File(\"keras_model.h5\", mode=\"r+\")\n",
    "model_config_string = f.attrs.get(\"model_config\")\n",
    "if model_config_string.find('\"groups\": 1,') != -1:\n",
    "    print(\"Found groups, deleting... \",end=\"\")\n",
    "    model_config_string = model_config_string.replace('\"groups\": 1,', '')\n",
    "    f.attrs.modify('model_config', model_config_string)\n",
    "    f.flush()\n",
    "    model_config_string = f.attrs.get(\"model_config\")\n",
    "    assert model_config_string.find('\"groups\": 1,') == -1\n",
    "    print(\"done\")\n",
    "else:\n",
    "    print(\"No groups found. Is the file \\\"keras_model.h5\\\" in the folder?\")\n",
    "f.close()\n",
    "```\n",
    "\n",
    "Als bovenstaande code uitgevoerd wordt krijgt men normaal volgende melding:\n",
    "> Found groups, deleting... done\n",
    "\n",
    "Indien je nogmaals deze code uitvoert krijg je volgende melding\n",
    "> No groups found. Is the file \"keras_model.h5\" in the folder?\n",
    "\n",
    "Dit betekent dat het model reeds gepatched is (wat goed is). Indien je meteen bovenstaande melding krijgt is de oorzaak dat het model niet in dezelfde map staat als het script.\n",
    "\n",
    "Indien de code nu gestart wordt zou je beeld moeten krijgen (herschaald naar het model) en in de CLI de evaluatie van het AI model. Indien de AI evaluatie niet optimaal is kan er nog getest worden met het beeld te spiegelen (bij een webcam wordt dit in de driver gespiegeld, dus kunnen we het terug goed zetten), en dit door toevoegen van volgende lijn code na regel 22 in ons script:\n",
    "\n",
    "```python\n",
    "image = cv2.flip(image, 1) \n",
    "```\n",
    "_Ik heb dit nog niet uitvoerig getest, daar ik nog geen optimaal model heb gegenereerd._\n",
    "\n",
    "## Interfacen met hardware\n",
    "\n",
    "Met bovenstaande uitleg bekomen we een identieke werking als wat we bekwamen in Google TM. De meerwaarde die we nu kunnen bekomen is dat we ons Python script probleemloos kunnen laten communiceren met hardware. Vanuit IoT standpunt zou dit het best gebeuren over een draadloos netwerk, maar ook dit valt buiten het tijdsbestek van deze workshop. \n",
    "\n",
    "Een alternatieve (eenvoudigere) manier is gebruik maken van een seri√´le verbinding tussen onze computer en een microcontroller. De workshop is uitgewerkt voor zowel een microcontroller die kan geprogrammeerd worden in C++ (richting ICW) of via MicroPython (TW&E). _Natuurlijk is dit niet bindend en kiest de leerling zelf welke programmeertaal hij wil gebruiken._\n",
    "\n",
    "```{figure} ./images/serial_connection.png\n",
    ":width: 400px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Seri√´le verbinding tussen computer (Python) en microcontroller.\n",
    "```\n",
    "\n",
    "### Python (zender)\n",
    "\n",
    "Met minimale aanpassingen aan ons script kunnen wij gebruik maken van een seri√´le verbinding op onze PC. Op het moment dat wij onze microcontroller verbinden met de PC wordt een seri√´le verbinding aangemaakt, die in Windows altijd een naam krijgt als `COM<x>` waarbij `<x>` een getal is. Via _apparaatbeheer_ in windows kunnen we controleren op welk nummer onze microcontroller verbonden is. In onderstaand voorbeeld is dit `COM3`. Het is belangrijk dat wij dit weten, aangezien we dit gaan moeten aanpassen in onze code.\n",
    "\n",
    "```{figure} ./images/apparaatbeheer.png\n",
    ":width: 500px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Opzoeken via apparaatbeheer wat het nummer is van de seri√´le verbinding.\n",
    "```\n",
    "Over deze seri√´le verbinding gaan we vervolgens onze data sturen die van toepassing is. Voor ons voorbeeld zullen we gebruik maken van volgende opbouw:\n",
    "`<class nr> <class percentage> <class name>`, waarbij ieder gedeelte gescheiden is door een spatie. Dit laat ons toe eenvoudig op te splitsen zodat we terug beschikking hebben over de informatie als aparte delen. _Het is de leerling natuurlijk vrij een totaal ander formaat te kiezen afhankelijk van de noden van het project. Dit formaat is puur als voorbeeld om te tonen dat alle relevante informatie kan verstuurd worden om vervolgens hergebruikt te worden in onze verwerkende code._\n",
    "\n",
    "Voegen we hiervoor volgende lijnen code toe aan het begin van het script:\n",
    "\n",
    "```python\n",
    "PORT = \"COM3\"\n",
    "import serial\n",
    "ser = serial.Serial(PORT, baudrate=115200, timeout=1)\n",
    "```\n",
    "In de loop van het script, net onder het afdrukken van de _prediction_ en _confidence score_, plaatsen we volgende lijntjes code bij:\n",
    "\n",
    "```python\n",
    "class_nr = class_name[0]\n",
    "class_str = class_name[2:]\n",
    "class_eq = str(np.round(confidence_score * 100))[:-2]\n",
    "```\n",
    "\n",
    "Afhankelijk of we bij de ontvanger gebruik maken van C++ of MicroPython moet hierbij nog volgende lijntjes code toegevoegd worden:\n",
    "\n",
    "\n",
    "```python\n",
    "arduinoString = class_nr + \" \" + class_eq + \" \" + class_str\n",
    "ser.write(arduinoString.encode())\n",
    "```\n",
    "\n",
    "```python\n",
    "arduinoString = class_nr + \" \" + class_eq + \" \" + class_str\n",
    "pythonString = \"process_data(\\\"\" + arduinoString[:-1] + \"\\\")\"\n",
    "ser.write(b\"\\x01\\x05A\\x01\" + pythonString.encode() + b\"\\x04\")\n",
    "```\n",
    "\n",
    "De code voor MicroPython is uitgebreider dan deze voor C++, dit omwille van het feit dat we moeten werken via [REPL](https://en.wikipedia.org/wiki/Read‚Äìeval‚Äìprint_loop). We moeten hiervoor de ontvanger als eerste in RAW mode plaatsen, dan ons commando doorsturen, en dan verwerken. Niet enkel de code is hierdoor uitgebreider, ook de grootte van het bericht die verstuurd wordt zal groter zijn (zie verder).\n",
    "\n",
    "Als alles goed gaat, zullen we geen foutmeldingen krijgen. We zullen echter wel niet gewijzigd zien aan de uitwerking van onze code. Op de achtergrond worden nu echter wel berichten serieel verzonden over de interface. Het plaatsen van een logic analyser op de pinnen 1 en 3 van onze ESP32 (die standaard UART0 zijn) geeft ons volgend beeld voor achtereenvolgens C++ en MicroPython:\n",
    "\n",
    "```{figure} ./images/ser_tx_cpp.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Seri√´le data voor C++ met daarin \"0 96 up\".\n",
    "```\n",
    "\n",
    "```{figure} ./images/ser_tx_micropython.png\n",
    ":width: 750px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Seri√´le data voor MicroPython met daarin \"0 96 up\".\n",
    "```\n",
    "\n",
    "Het verzendgedeelte is hiermee werkende bevonden. Nu rest ons alleen nog code te schrijven die de hardware zal aansturen.\n",
    "\n",
    "```{figure} ./images/arduino_led.png\n",
    ":width: 400px\n",
    ":align: left\n",
    ":figwidth: image\n",
    ":figclass: myBlockImg\n",
    "\n",
    "Twee LED's (rood en groen) verbonden met een Arduino UNO bordje.\n",
    "```\n",
    "\n",
    "### Arduino (ontvanger)\n",
    "\n",
    "De code voor Arduino bestaat uit enkele delen:\n",
    "1) `setup()`: hier wordt de hardware correct ingesteld. Voor de demo worden er twee pinnen voorzien van een LED (rood en groen), en zal de rode LED gebruikt worden voor duim neerwaarts en de groene LED voor duim opwaarts.\n",
    "2) `processUart()`: dit gedeelte van de code haalt karakters op van de seri√´le interface. Wanneer een volledige lijn is ontvangen wordt deze doorgegeven naar de functie `processData()`.\n",
    "3) `processData(String input)`: De data die ontvangen is van de seri√´le input wordt hier verwerkt. Als eerste worden de drie verschillende variabelen opgesplitst om vervolgens hiermee iets te doen. De code is hier zodanig geschreven dat de correcte LED oplicht wanneer de waarschijnlijkheid boven de 80% zit.\n",
    "\n",
    "```cpp\n",
    "#define GREEN 2  //dit is de pin voor een ESPduino32. Voor een Arduino UNO moet dit A0 zijn\n",
    "#define RED   4  //dit is de pin voor een ESPduino32. Voor een Arduino UNO moet dit A1 zijn\n",
    "\n",
    "void setup(){\n",
    "  Serial.begin(115200);\n",
    "  pinMode(RED,OUTPUT);\n",
    "  pinMode(GREEN,OUTPUT);\n",
    "  digitalWrite(RED,LOW);\n",
    "  digitalWrite(GREEN,LOW);\n",
    "}\n",
    "\n",
    "void processData(String input){\n",
    "  uint8_t number1, percentage;\n",
    "  // Zoek de posities van de eerste en tweede spatie\n",
    "  int8_t firstSpace = input.indexOf(' ');\n",
    "  int8_t secondSpace = input.indexOf(' ', firstSpace + 1);\n",
    "  if(firstSpace==-1||secondSpace==-1){\n",
    "    Serial.println(\"Fout: onjuiste invoer!\");\n",
    "    return;\n",
    "  }\n",
    "  //Extraheer en converteer de waarden\n",
    "  number1 = input.substring(0, firstSpace).toInt();\n",
    "  percentage = input.substring(firstSpace + 1, secondSpace).toInt();\n",
    "  //Extraheer de resterende tekst\n",
    "  String textString = input.substring(secondSpace + 1);\n",
    "  // Print het resultaat\n",
    "  Serial.printf(\"(%d,%d,%s)\\n\",number1,percentage,textString);\n",
    "  // doe nuttige dingen\n",
    "  if(number1==0 && percentage>80){\n",
    "    digitalWrite(GREEN,HIGH);\n",
    "  }else{\n",
    "    digitalWrite(GREEN,LOW);\n",
    "  }\n",
    "  if(number1==1 && percentage>80){\n",
    "    digitalWrite(RED,HIGH);\n",
    "  }else{\n",
    "    digitalWrite(RED,LOW);\n",
    "  }\n",
    "}\n",
    "\n",
    "static String receivedLine = \"\";  // Opslag voor inkomende regel\n",
    "void processUart(){\n",
    "  while(Serial.available()){  // Controleer of er gegevens binnenkomen\n",
    "    char incomingChar = Serial.read();  // Lees √©√©n karakter in\n",
    "    if(incomingChar=='\\n'){  // Controleer of een nieuwe regel is voltooid\n",
    "      //do necessary stuff\n",
    "      processData(receivedLine);\n",
    "      receivedLine = \"\";  // Reset de buffer\n",
    "    }else if(incomingChar!='\\r'){  // Vermijd '\\r' (carriage return)\n",
    "      receivedLine += incomingChar;  // Voeg karakter toe aan stringbuffer\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "void loop(){\n",
    "  processUart();\n",
    "}\n",
    "```\n",
    "\n",
    "In de code is eveneens nog het commando `Serial.print()` opgenomen. Hiermee wordt data teruggestuurd naar het Python script, maar in het Python script wordt voor de eenvoud van de code hier niets mee gedaan. Mocht er iets niet werken, dan kan deze data op de CLI weergegeven worden door volgend stuk aan het Python script toe te voegen (of je kan het eveneens controleren via een logic analyser):\n",
    "\n",
    "```python\n",
    "bytesToRead = ser.inWaiting()\n",
    "print(ser.read(bytesToRead))\n",
    "```\n",
    "\n",
    "### MicroPython (ontvanger)\n",
    "\n",
    "De MicroPython code werkt op een totaal ander principe. We zouden ook een identieke code als in C++ kunnen schrijven, maar als we willen gebruik maken van de USB verbinding (USB2Serial) moeten we werken via REPL. Dit betekent dat we een script gaan inladen waarin gewoonweg de functie in zit die een string moet decoderen.\n",
    "\n",
    "```python\n",
    "import machine\n",
    "\n",
    "GREEN = machine.Pin(2, machine.Pin.OUT)\n",
    "RED = machine.Pin(4, machine.Pin.OUT)\n",
    "\n",
    "def setup():\n",
    "    GREEN.value(0)\n",
    "    RED.value(0)\n",
    "\n",
    "def process_data(input_line):\n",
    "    try:\n",
    "        # Splits de string in 3 delen: cijfer, percentage en tekst\n",
    "        parts = input_line.strip().split(\" \", 2)\n",
    "        \n",
    "        if len(parts) < 3:\n",
    "            print(\"Fout: onjuiste invoer!\")\n",
    "            return\n",
    "        \n",
    "        number1 = int(parts[0])  # Eerste getal (0-9)\n",
    "        percentage = int(parts[1])  # Percentage (0-100)\n",
    "        text = parts[2]  # Overige tekst\n",
    "        \n",
    "        # Print de ontvangen waarden\n",
    "        print(f\"({number1},{percentage},{text})\")\n",
    "        \n",
    "        # Doe nuttige dingen met LEDs\n",
    "        GREEN.value(1 if number1 == 0 and percentage > 80 else 0)\n",
    "        RED.value(1 if number1 == 1 and percentage > 80 else 0)\n",
    "\n",
    "    except ValueError:\n",
    "        print(\"Fout: kon invoer niet omzetten naar getal!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    setup()\n",
    "```\n",
    "\n",
    "Aangezien dit script iedere keer moet inladen wanneer de microcontroller start gaan we dit script opslaan als `main.py` op de microcontroller zelf. Bij het starten worden de LED's geconfigureerd en de functie `process_data()` geregistreerd. Indien we vervolgens via REPL de functie `process_data()` aanroepen met als argument onze string data zal dit vervolgens verwerkt worden.\n",
    "\n",
    "## Uitbreidingen\n",
    "\n",
    "De leerlingen die eerder klaar zijn dan voorzien mogen de code op de microcontroller uitbreiden. Door het toevoegen van een servo kan een duim gepositioneerd worden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
